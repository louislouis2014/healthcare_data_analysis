{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1.1 Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "\n",
    "# plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as po\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# colors\n",
    "import colorlover as cl\n",
    "from IPython.display import HTML\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "po.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1.2 Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def flatten_list(lst):\n",
    "    flat_list = []\n",
    "    \n",
    "    for val in lst:\n",
    "        if isinstance(val, list):\n",
    "            flat_list += flatten_list(val)\n",
    "        else:\n",
    "            flat_list.append(val)\n",
    "    \n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sum_row_vals(series):\n",
    "    out = ''\n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        out += str(series[i]) + '  '\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_color_scale(index):\n",
    "    color_scale = []\n",
    "    \n",
    "    try:\n",
    "        trace_cnt = len(index.labels[0])\n",
    "    except AttributeError:\n",
    "        trace_cnt = len(index)\n",
    "    \n",
    "    while trace_cnt > 0:\n",
    "        if trace_cnt > 12:\n",
    "            color_scale += cl.scales['12']['qual']['Paired']\n",
    "            trace_cnt -= 12\n",
    "        elif trace_cnt > 2:\n",
    "            color_scale += cl.scales[str(trace_cnt)]['qual']['Paired']\n",
    "            trace_cnt = 0\n",
    "        else:\n",
    "            color_scale += cl.scales['3']['qual']['Paired'][:trace_cnt]\n",
    "            trace_cnt = 0\n",
    "    \n",
    "    return color_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 State Level Population Estimates, 1900-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_census_data_1900_1969(url, header=0, nrows=0, years=None):\n",
    "    # Read in raw data\n",
    "    df = pd.read_fwf(\n",
    "        url,\n",
    "        header = header,\n",
    "        nrows = nrows\n",
    "    )\n",
    "\n",
    "    # Pull Column Names\n",
    "    new_col_nms = flatten_list(['State'] + list(df.columns.str.split('\\s+')))\n",
    "    \n",
    "    # Flatten DF into single columns\n",
    "    if df.shape[1] > 1:\n",
    "        df = pd.DataFrame(df.apply(sum_row_vals, axis=1))\n",
    "    \n",
    "    # Split data into multiple columns\n",
    "    df = df.iloc[:, 0].str.strip().str.split('\\s{2,}', expand=True)\n",
    "\n",
    "    # Rename Columns\n",
    "    df = df.rename(columns = {col: new_col for col, new_col in zip(df.columns, new_col_nms)})\n",
    "    \n",
    "    # Drop Aggregate Columns\n",
    "    non_states = df['State'].isin(['U.S.', 'Northeast', 'North Central', 'South', 'West', 'Midwest', 'REGIONS:', 'STATES:'])\n",
    "    df = df.loc[-non_states].reset_index(drop = True)\n",
    "    \n",
    "    # Drop null rows & columns\n",
    "    df = df.dropna(how='any').reset_index(drop = True)\n",
    "    \n",
    "    # Conver String Numbers to Integers\n",
    "    f = (lambda col: col.str.replace(',', ''))\n",
    "    converted_data = df.iloc[:, 1:].apply(f, axis = 1).astype(np.int64)\n",
    "    df = df.assign(**{col: converted_data[col].values for col in converted_data.columns})\n",
    "    \n",
    "    # Flag duplicate columns\n",
    "    new_cols = [df.columns[i] if df.columns[i] != df.columns[i+1] else 'dupe' for i in range(len(df.columns)-1)] + [df.columns[-1]]\n",
    "    df.columns = new_cols\n",
    "    \n",
    "    # Logic to drop irrelevant columns, and duplicate columns (take the second one)\n",
    "    if years is not None:\n",
    "        accepted_cols = ['State'] + [str(yr) for yr in range(years[0], years[1]+1)]\n",
    "        df = df.loc[:, df.columns.isin(accepted_cols)]\n",
    "    \n",
    "    # Multiply by 1000 if file data is represented \"in thousands\"\n",
    "    response = requests.get(url)\n",
    "    if 'in thousands' in response.text[:500].lower():\n",
    "        thousands = df.loc[:, df.dtypes == np.int64] * 1000\n",
    "        df = df.assign(**{col: thousands[col].values for col in thousands.columns})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_census_data_1970_1989(url, header=0, nrows=0, years=None):\n",
    "    # Read in raw data\n",
    "    df = pd.read_fwf(\n",
    "        url,\n",
    "        header = header,\n",
    "        nrows = nrows\n",
    "    )\n",
    "\n",
    "    # Pull Column Names\n",
    "    new_col_nms = pd.Series(flatten_list(df.columns.str.split('\\s+'))) \\\n",
    "                    .str.replace('.*/', '') \\\n",
    "                    .str.replace('cen', '') \\\n",
    "                    .str.replace('St', 'State')\n",
    "\n",
    "    new_col_nms = new_col_nms.where(\n",
    "        -new_col_nms.str.isnumeric(),\n",
    "        lambda x: '19' + x\n",
    "    ).tolist()\n",
    "\n",
    "    # Flatten DF into single columns\n",
    "    if df.shape[1] > 1:\n",
    "        df = pd.DataFrame(df.apply(sum_row_vals, axis=1))\n",
    "\n",
    "    # # Split data into multiple columns\n",
    "    df = df.iloc[:, 0].str.strip().str.split('\\s+', expand=True)\n",
    "\n",
    "    # # Rename Columns\n",
    "    if df.shape[1] > len(new_col_nms):\n",
    "        new_col_nms = (['State'] * (df.shape[1] - len(new_col_nms))) + new_col_nms\n",
    "\n",
    "    df = df.rename(columns = {col: new_col for col, new_col in zip(df.columns, new_col_nms)})\n",
    "\n",
    "    # Flag duplicate columns\n",
    "    new_cols = [df.columns[i] if df.columns[i] != df.columns[i+1] else 'dupe' for i in range(len(df.columns)-1)] + [df.columns[-1]]\n",
    "    df.columns = new_cols\n",
    "\n",
    "    # Drop Aggregate Columns\n",
    "    non_states = df['State'].isin(['US'])\n",
    "    df = df.loc[-non_states].reset_index(drop = True)\n",
    "\n",
    "    # # Drop null rows & columns\n",
    "    # df = df.dropna(how='any').reset_index(drop = True)\n",
    "\n",
    "    # Convert String Numbers to Integers\n",
    "    f = (lambda col: col.str.replace(',', ''))\n",
    "    converted_data = df.loc[:, df.columns.str.isnumeric()].apply(f, axis = 1).astype(np.int64)\n",
    "    df = df.assign(**{col: converted_data[col].values for col in converted_data.columns})\n",
    "\n",
    "    # Logic to drop irrelevant columns, and duplicate columns (take the second one)\n",
    "    if years is not None:\n",
    "        accepted_cols = ['State'] + [str(yr) for yr in range(years[0], years[1]+1)]\n",
    "        df = df.loc[:, df.columns.isin(accepted_cols)]\n",
    "        \n",
    "    # Multiply by 1000 if file data is represented \"in thousands\"\n",
    "    response = requests.get(url)\n",
    "    if 'in thousands' in response.text[:500].lower():\n",
    "        thousands = df.loc[:, df.dtypes == np.int64] * 1000\n",
    "        df = df.assign(**{col: thousands[col].values for col in thousands.columns})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "parameters = pd.DataFrame({\n",
    "    'years' : [\n",
    "        (1900, 1905), (1906, 1909), \n",
    "        (1910, 1915), (1916, 1919), \n",
    "        (1920, 1925), (1926, 1929),\n",
    "        (1930, 1935), (1936, 1939),\n",
    "        (1940, 1945), (1946, 1949),\n",
    "        (1950, 1954), (1955, 1959),\n",
    "        (1960, 1964), (1965, 1969),\n",
    "        (1970, 1975), (1976, 1979),\n",
    "        (1980, 1984), (1985, 1989)\n",
    "    ],\n",
    "    'header': [11, 66, 11, 66, 11, 66, 11, 66,  9, 64, 16, 81, 11, 69,  9, 62, 6, 62],\n",
    "    'nrows' : [56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 61, 61, 61, 61, 51, 51, 52, 52],\n",
    "    'url'   : ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st0009ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st1019ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st2029ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st3039ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st4049ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st5060ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st6070ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st7080ts.txt'] * 2 + \\\n",
    "                ['https://www2.census.gov/programs-surveys/popest/tables/1980-1990/state/asrh/st8090ts.txt'] * 2,\n",
    "    'func'  : ([read_census_data_1900_1969] * 14) + ([read_census_data_1970_1989] * 4)\n",
    "}, columns = ['years', 'header', 'nrows', 'url', 'func'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Read Individual Row \n",
    "row = 2\n",
    "df = parameters.iloc[row].func(\n",
    "    url = parameters.iloc[row].url,\n",
    "    header = parameters.iloc[row].header,\n",
    "    nrows = parameters.iloc[row].nrows,\n",
    "    years = parameters.iloc[row].years\n",
    ")\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in Payments Data\n",
    "pop = pd.concat(\n",
    "    (\n",
    "        parms.func(\n",
    "            url = parms.url,\n",
    "            header = parms.header,\n",
    "            nrows = parms.nrows,\n",
    "            years = parms.years\n",
    "        ).melt(\n",
    "            id_vars='State', \n",
    "            var_name='Year', \n",
    "            value_name='Population'\n",
    "        )\n",
    "        for _, parms in parameters.iterrows()\n",
    "    ),\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Projected Future Health Expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pop.pivot_table(\n",
    "    values = 'Population', \n",
    "    index = 'State',\n",
    "    columns = 'Year',\n",
    "    aggfunc = np.sum,\n",
    "    fill_value = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def stacked_line_plot(df, normalize=False, cumulative_text=False, color_scale=None, nbr_form=None, inline=False):\n",
    "    # set defaults\n",
    "    df = (df if not normalize else (df / df.sum(axis=0)))\n",
    "    color_scale = (color_scale if color_scale is not None else get_color_scale(df.index))\n",
    "    print(len(color_scale))\n",
    "    \n",
    "    if nbr_form is None:    \n",
    "        if normalize:\n",
    "            nbr_form = (lambda x: '{:.1f}%'.format(x * 100))\n",
    "        else:\n",
    "            nbr_form = (lambda x: '${:.1f}'.format(x / 1000))\n",
    "\n",
    "    # Containers\n",
    "    traces = []\n",
    "    y = df.cumsum()\n",
    "    \n",
    "    if cumulative_text:\n",
    "        y_txt = y.applymap(nbr_form)\n",
    "    else:\n",
    "        y_txt = df.applymap(nbr_form)\n",
    "    \n",
    "    # Build Traces\n",
    "    for data, data_txt, color in zip(y.iterrows(), y_txt.iterrows(), color_scale):\n",
    "        trace = go.Scatter(\n",
    "            x = data[1].index,\n",
    "            y = data[1].values,\n",
    "            text = data_txt[1].values,\n",
    "            hoverinfo = 'x+text',\n",
    "            mode = 'lines',\n",
    "            line = dict(\n",
    "                width = 1,\n",
    "                color = color\n",
    "            ),\n",
    "            fill = 'tonexty',\n",
    "            name = data[0]\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "    \n",
    "    if inline:\n",
    "        po.iplot(fig, filename='my-stacked-area-plot-hover')\n",
    "    else:\n",
    "        po.plot(fig, filename='my-stacked-area-plot-hover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LB17108\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\plotly\\offline\\offline.py:459: UserWarning:\n",
      "\n",
      "Your filename `my-stacked-area-plot-hover` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    " stacked_line_plot(\n",
    "    a.loc[a.sum(axis=1).nlargest(10).index],\n",
    "    normalize = False,\n",
    "    nbr_form = (lambda x: '{:.2f} M'.format(x / 1000000))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
